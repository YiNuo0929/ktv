from faster_whisper import WhisperModel
from opencc import OpenCC
from tqdm import tqdm
import argparse


# è¨­å®šæ¨¡å‹èˆ‡æª”æ¡ˆè·¯å¾‘
model = WhisperModel("medium", compute_type="int8")  # ä½ å¯æ›æˆ tiny æˆ– medium
cc = OpenCC('s2t')
parser = argparse.ArgumentParser()
parser.add_argument("--input", "-i", required=True, help="äººè²éŸ³è¨Šæª” (.wav)")
parser.add_argument("--output", "-o", required=True, help="è¼¸å‡ºå­—å¹•æª” (.srt)")
args = parser.parse_args()

input_audio = args.input
output_srt = args.output

# åŸ·è¡Œè½‰éŒ„
print("ğŸ™ï¸ é–‹å§‹è½‰éŒ„éŸ³è¨Šï¼ˆå«é€å­—æ™‚é–“ï¼‰...")
segments, _ = model.transcribe(input_audio, word_timestamps=True)

# æ ¼å¼åŒ–æ™‚é–“
def format_timestamp(seconds):
    hrs = int(seconds // 3600)
    mins = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hrs:02}:{mins:02}:{secs:02},{millis:03}"

# å¯«å…¥ .srt
with open(output_srt, "w", encoding="utf-8") as f:
    for i, segment in enumerate(tqdm(segments, desc="ğŸ“ ç”Ÿæˆé€å­— SRT")):
        words = segment.words
        if not words:
            continue
        start = format_timestamp(words[0].start)  # ğŸ¯ ä»¥ç¬¬ä¸€å€‹å­—çš„æ™‚é–“ç‚ºèµ·é»
        end = format_timestamp(words[-1].end)
        text = cc.convert("".join([w.word for w in words]).strip())
        f.write(f"{i+1}\n{start} --> {end}\n{text}\n\n")

print(f"âœ… ç²¾ç¢ºé€å­—å­—å¹•å„²å­˜è‡³ï¼š{output_srt}")